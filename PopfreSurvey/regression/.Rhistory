ggplot(BeasLogit1, aes(x=Herbaceaus, y=Fall2024)) + geom_point() +
stat_smooth(method="glm", color="purple", se=F,
method.args = list(family=binomial))
View(BeasLogit1)
# Plot Predicted data and original data points
names(BeasLogit1)
ggplot(data = BeasLogit1, aes(x = Herbaceaus, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = Herbaceaus, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
model <- glm(`Fall2024` ~ WaterSurfaceElevation + WaterSurfaceElevationBINOM + HerbaceausBINOM + LightBINOM,
data = BeasleyPopSurv, family = binomial)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
ChildsPopSurv <- read.csv("ChildsRegression.csv")
ChildsPopSurv <- read.csv("ChildsRegresssion.csv")
View(ChildsPopSurv)
ChildsPopSurv$LightBINOM <- ChildsPopSurv$Light^2
ChildsPopSurv$HerbaceausBINOM <- ChildsPopSurv$Herbaceaus^2
ChildsLogit1 <- glm(Fall2024 ~ LightBINOM + HerbaceausBINOM , data = ChildsPopSurv, family = "binomial")
summary(ChildsLogit1)
## Confidence Intervals using profiled log-likelihood
confint(ChildsLogit1)
## Confidence Intervals using standard errors
confint.default(ChildsLogit1)
wald.test(b = coef(ChildsLogit1), Sigma = vcov(ChildsLogit1), L = 1)
ggplot(data = ChildsPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
# Prediction accuracy
observed.classes <- test.data$diabetes
#Prediction accuracy of the stepwise logistic regression model
# Make predictions
probabilities <- predict(step.model, test.data, type = "response")
#Compare the full and the stepwise models
# Make predictions
probabilities <- full.model %>% predict(BeasleyPopSurv, type = "response")
#Compare the full and the stepwise models
# Make predictions
probabilities <- model %>% predict(BeasleyPopSurv, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
probabilities <- model %>% predict(BeasleyPopSurv, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
ggplot(data = ChildsPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ChildsLogit1 <- glm(Fall2024 ~ LightBINOM + HerbaceausBINOM , data = ChildsPopSurv, family = "binomial")
summary(ChildsLogit1)
# Full model predictions
full_probabilities <- predict(full.model, test_data, type = "response")
full_probabilities <- predict(model, test_data, type = "response")
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(BeasleyPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- BeasleyPopSurv[train_indices, ]
test_data <- BeasleyPopSurv[-train_indices, ]
model <- glm(`Fall2024` ~ WaterSurfaceElevation + WaterSurfaceElevationBINOM + HerbaceausBINOM + LightBINOM,
data = BeasleyPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
summary(model)
summary(step.model)
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
full_accuracy <- mean(full_predicted == observed)
observed <- BeasleyPopSurv$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(BeasleyPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- BeasleyPopSurv[train_indices, ]
test_data <- BeasleyPopSurv[-train_indices, ]
observed <- BeasleyPopSurv$Fall2024
#BRAP
model <- glm(`Fall2024` ~ WaterSurfaceElevation + WaterSurfaceElevationBINOM + HerbaceausBINOM + LightBINOM,
data = BeasleyPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
# Full model predictions
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
# Stepwise model predictions
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
# Model accuracy
# Observed outcomes
observed <- test_data$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
cat("Full model accuracy:", full_accuracy, "\n")
cat("Stepwise model accuracy:", step_accuracy, "\n")
#Prediction accuracy of the stepwise logistic regression model
# Make predictions
probabilities <- predict(step.model, test.data, type = "response")
#Prediction accuracy of the stepwise logistic regression model
# Make predictions
probabilities <- predict(step.model, observed, type = "response")
View(BeasleyPopSurv)
vif(full_model)
library(car)
vif(full_model)
vif(model)
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(BeasleyPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- BeasleyPopSurv[train_indices, ]
test_data <- BeasleyPopSurv[-train_indices, ]
observed <- BeasleyPopSurv$Fall2024
#BRAP
model <- glm(`Fall2024` ~ WaterSurfaceElevation + WaterSurfaceElevationBINOM + HerbaceausBINOM + LightBINOM,
data = BeasleyPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
# Full model predictions
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
# Stepwise model predictions
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
# Model accuracy
# Observed outcomes
observed <- test_data$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
cat("Full model accuracy:", full_accuracy, "\n")
cat("Stepwise model accuracy:", step_accuracy, "\n")
model <- glm(`Fall2024` ~  HerbaceausBINOM + LightBINOM,
data = ChildsPopSurv, family = binomial)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
summary(model)
summary(step.model)
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(ChildsPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- ChildsPopSurv[train_indices, ]
test_data <- ChildsPopSurv[-train_indices, ]
observed <- ChildsPopSurv$Fall2024
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(ChildsPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- ChildsPopSurv[train_indices, ]
test_data <- ChildsPopSurv[-train_indices, ]
observed <- ChildsPopSurv$Fall2024
model <- glm(`Fall2024` ~  HerbaceausBINOM + LightBINOM,
data = ChildsPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
# Full model predictions
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
# Stepwise model predictions
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
# Model accuracy
# Observed outcomes
observed <- test_data$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
cat("Full model accuracy:", full_accuracy, "\n")
cat("Stepwise model accuracy:", step_accuracy, "\n")
ggplot(data = ChildsPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
library(readxl)
Sheep <- read_xlsx("ImageryStatistics.csv", sheet = "Sheep")
Sheep <- read_xlsx("ImageryStatistics.xlsx", sheet = "Sheep")
Sheep <- read_xlsx("ImageryStatistics150m.xlsx", sheet = "Sheep")
Sheep <- read_xlsx("ImageryStatistics150m.xlsx", sheet = "Sheep")
result <- chisq.test(Sheep)
# Print results
print(result)
#Bonferoni adjust the p-value for the number of comparisons to equal p = 0.05
n = 5 # number of comparisons
Padj <- 0.05/n
print (Padj)
View(Sheep)
result <- chisq.test(Sheep)
# Print results
print(result)
#Bonferoni adjust the p-value for the number of comparisons to equal p = 0.05
n = 7 # number of comparisons
Padj <- 0.05/n
print (Padj)
Chlids <- read_xlsx("ImageryStatistics150m.xlsx", sheet = "Childs")
BRAP <- read_xlsx("ImageryStatistics150m.xlsx", sheet = "BRAP"
result <- chisq.test(Sheep)
result <- chisq.test(Sheep)
# Print results
print(result)
#Bonferoni adjust the p-value for the number of comparisons to equal p = 0.05
n = 7 # number of comparisons
Padj <- 0.05/n
print (Padj)
result <- chisq.test(Childs)
Chlids <- read_xlsx("ImageryStatistics150m.xlsx", sheet = "Childs")
result <- chisq.test(Childs)
Childs <- read_xlsx("ImageryStatistics150m.xlsx", sheet = "Childs")
result <- chisq.test(Childs)
# Print results
print(result)
#Bonferoni adjust the p-value for the number of comparisons to equal p = 0.05
n = 7 # number of comparisons
Padj <- 0.05/n
print (Padj)
setwd("C:/Users/qm43/Box/VerdeRiverWatershed/QRMPopFre/RegressionCode")
setwd("C:\Users\qm43\Box\VerdeRiverWatershed\QRMPopFre\RegressionCode")
setwd("C:?/Users/qm43/Box/VerdeRiverWatershed/QRMPopFre/RegressionCode")
setwd("C:/Users/qm43/Box/VerdeRiverWatershed/QRMPopFre/RegressionCode")
BeasleyPopSurv <- read.csv("regression.csv")
ChildsPopSurv <- read.csv("ChildsRegresssion.csv")
BeasleyPopSurv$LightBINOM <- BeasleyPopSurv$Light^2
BeasleyPopSurv$HerbaceausBINOM <- BeasleyPopSurv$Herbaceaus^2
BeasleyPopSurv$WaterSurfaceElevationBINOM <- BeasleyPopSurv$WaterSurfaceElevation^2
#For Childs
ChildsPopSurv$LightBINOM <- ChildsPopSurv$Light^2
ChildsPopSurv$HerbaceausBINOM <- ChildsPopSurv$Herbaceaus^2
BeasLogit1 <- glm(Fall2024 ~ LightBINOM + HerbaceausBINOM , data = BeasleyPopSurv, family = "binomial")
#BeasLogit <- glm(TF ~ DistChan + DistChan2 + DGW + DGW2 + PercFines + PercFines2, data = BeasleyPopSurv, family = "binomial")
summary(BeasLogit1)
BeasLogit1 <- glm(Fall2024 ~ LightBINOM + HerbaceausBINOM , data = BeasleyPopSurv, family = "binomial")
#BeasLogit <- glm(TF ~ DistChan + DistChan2 + DGW + DGW2 + PercFines + PercFines2, data = BeasleyPopSurv, family = "binomial")
summary(BeasLogit1)
## Confidence Intervals using profiled log-likelihood
confint(BeasLogit1)
## Confidence Intervals using standard errors
confint.default(BeasLogit1)
wald.test(b = coef(BeasLogit1), Sigma = vcov(BeasLogit1), L = 1)
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(BeasleyPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- BeasleyPopSurv[train_indices, ]
test_data <- BeasleyPopSurv[-train_indices, ]
observed <- BeasleyPopSurv$Fall2024
model <- glm(`Fall2024` ~ WaterSurfaceElevation + WaterSurfaceElevationBINOM + HerbaceausBINOM + LightBINOM,
data = BeasleyPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
#Coef
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
# Full model predictions
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
# Stepwise model predictions
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
# Model accuracy
# Observed outcomes
observed <- test_data$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
cat("Full model accuracy:", full_accuracy, "\n")
cat("Stepwise model accuracy:", step_accuracy, "\n")
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(ChildsPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- ChildsPopSurv[train_indices, ]
test_data <- ChildsPopSurv[-train_indices, ]
observed <- ChildsPopSurv$Fall2024
model <- glm(`Fall2024` ~  HerbaceausBINOM + LightBINOM,
data = ChildsPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
# Full model predictions
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
# Stepwise model predictions
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
# Model accuracy
# Observed outcomes
observed <- test_data$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
cat("Full model accuracy:", full_accuracy, "\n")
cat("Stepwise model accuracy:", step_accuracy, "\n")
#Plot
ggplot(data = ChildsPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
#Plot
ggplot(data = BeasleyPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = ChildsPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = ChildsPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
labs(title = "Childs")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = ChildsPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
labs(title = "Childs")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
labs(title = "BRAP")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = ChildsPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
labs(title = "BRAP")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = ChildsPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
labs(title = "Childs")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
# Perform the chi-square test
result <- chisq.test(Childs)
# Print results
print(result)
#Bonferoni adjust the p-value for the number of comparisons to equal p = 0.05
n = 7 # number of comparisons
Padj <- 0.05/n
print (Padj)
# Perform the chi-square test
result <- chisq.test(BRAP)
BRAP <- read_xlsx("ImageryStatistics150m.xlsx", sheet = "BRAP")
result <- chisq.test(BRAP)
# Print results
print(result)
#Bonferoni adjust the p-value for the number of comparisons to equal p = 0.05
n = 7 # number of comparisons
Padj <- 0.05/n
print (Padj)
#BRAP. Herbaceaus WAS significant
ggplot(data = BeasleyPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
labs(title = "BRAP")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
#Plot Light. Light was found to be signficant for both
ggplot(data = ChildsPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
labs(title = "Childs")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
labs(title = "BRAP")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = ChildsPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
labs(title = "Childs")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
labs(title = "BRAP")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
#Plots Herbaceaus
#BRAP. Herbaceaus WAS significant. Seems to be more of a linear trend
ggplot(data = BeasleyPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
labs(title = "BRAP")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
#Childs. Herbaceaus was NOT considered significant
ggplot(data = ChildsPopSurv, aes(x = HerbaceausBINOM, y = Fall2024)) +
geom_point() +
labs(title = "Childs")+
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(ChildsPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- ChildsPopSurv[train_indices, ]
test_data <- ChildsPopSurv[-train_indices, ]
observed <- ChildsPopSurv$Fall2024
model <- glm(`Fall2024` ~  HerbaceausBINOM + LightBINOM,
data = ChildsPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
# Full model predictions
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
# Stepwise model predictions
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
# Model accuracy
# Observed outcomes
observed <- test_data$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
cat("Full model accuracy:", full_accuracy, "\n")
cat("Stepwise model accuracy:", step_accuracy, "\n")
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(BeasleyPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- BeasleyPopSurv[train_indices, ]
test_data <- BeasleyPopSurv[-train_indices, ]
observed <- BeasleyPopSurv$Fall2024
model <- glm(`Fall2024` ~ WaterSurfaceElevation + WaterSurfaceElevationBINOM + HerbaceausBINOM + LightBINOM,
data = BeasleyPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
#Coef
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
# Full model predictions
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
# Stepwise model predictions
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
# Model accuracy
# Observed outcomes
observed <- test_data$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
cat("Full model accuracy:", full_accuracy, "\n")
cat("Stepwise model accuracy:", step_accuracy, "\n")
