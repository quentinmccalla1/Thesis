<<<<<<< Updated upstream
names_to = "Year",
values_to = "Area"
) %>%
mutate(Year = as.numeric(str_remove(Year, "X")))  # Convert "X2023" -> 2023 (numeric)
anova_results <- ImageryAreas_long %>%
group_by(Class) %>%
summarise(ANOVA_test = list(aov(Area ~ Year, data = cur_data()))) %>%
mutate(p_value = sapply(ANOVA_test, function(x) summary(x)[[1]][["Pr(>F)"]][1]))
View(anova_results)
tukey_results <- ImageryAreas_long %>%
group_by(Class.Sheep) %>%
summarise(Tukey = list(TukeyHSD(aov(Area ~ Year, data = cur_data()))))
tukey_results <- ImageryAreas_long %>%
group_by(Class) %>%
summarise(Tukey = list(TukeyHSD(aov(Area ~ Year, data = cur_data()))))
tukey_results <- ImageryAreas_long %>%
group_by(Class) %>%
mutate(Year = as.factor(Year)) %>%
summarise(Tukey = list(TukeyHSD(aov(Area ~ Year, data = cur_data()))))
tukey_results
View(tukey_results)
tukey_results %>%
mutate(Tukey_summary = map(Tukey, broom::tidy)) %>%
unnest(Tukey_summary) %>%
select(Class.Sheep, term, contrast, estimate, adj.p.value)
tukey_results %>%
mutate(Tukey_summary = map(Tukey, broom::tidy)) %>%
unnest(Tukey_summary) %>%
select(Class, term, contrast, estimate, adj.p.value)
tukey_results <- ImageryAreas_long %>%
group_by(Class) %>%
mutate(Year = as.factor(Year)) %>%
summarise(Tukey = list(TukeyHSD(aov(Area ~ Year, data = cur_data()))))
tukey_results %>%
mutate(Tukey_summary = map(Tukey, broom::tidy)) %>%
unnest(Tukey_summary) %>%
select(Class, term, contrast, estimate, adj.p.value)
View(anova_results)
tukey_results <- ImageryAreas_long %>%
mutate(Year = as.factor(Year)) %>%  # Ensure Year is categorical
group_by(Class.Sheep) %>%
summarise(Tukey = list(TukeyHSD(aov(Area ~ Year, data = cur_data()))))
tukey_results <- ImageryAreas_long %>%
mutate(Year = as.factor(Year)) %>%  # Ensure Year is categorical
group_by(Class) %>%
summarise(Tukey = list(TukeyHSD(aov(Area ~ Year, data = cur_data()))))
# Extract Tukey results into a readable format
tukey_results_clean <- tukey_results %>%
mutate(Tukey_summary = map(Tukey, function(x) {
tidy(x)  # Convert Tukey test results to a tibble
})) %>%
unnest(Tukey_summary) %>%
select(Class, term, contrast, estimate, adj.p.value)  # Ensure correct column names
ImageryAreas_long %>% group_by(Class, Year) %>% summarise(n = n(), .groups = "drop")
chi_data <- ImageryAreas_long %>%
filter(Year %in% c(2010, 2023)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area)) %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
chisq.test(as.matrix(chi_data))
pairwise.prop.test(as.matrix(chi_data), p.adjust.method = "bonferroni")
chi_data %>%
pivot_longer(cols = c("2010", "2023"), names_to = "Year", values_to = "Total_Area") %>%
ggplot(aes(x = Year, y = Total_Area, fill = rownames(chi_data))) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Land Cover Change from 2010 to 2023", y = "Total Area (m²)", x = "Year") +
theme_minimal()
years <- unique(ImageryAreas_long$Year)
years <- sort(as.numeric(years))  # Ensure years are sorted numerically
# Initialize a dataframe to store results
chi_results <- data.frame(Class = character(),
Year1 = integer(),
Year2 = integer(),
Chi_sq = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each class and compare each pair of years
for (class_name in unique(ImageryAreas_long$Class)) {
for (i in 1:(length(years) - 1)) {
for (j in (i + 1):length(years)) {
year1 <- years[i]
year2 <- years[j]
# Filter data for the specific class and years
chi_data <- ImageryAreas_long %>%
filter(Class == class_name & Year %in% c(year1, year2)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area), .groups = "drop") %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
# Check if data is sufficient for a test
if (nrow(chi_data) > 0 && all(!is.na(chi_data))) {
chi_test <- chisq.test(as.matrix(chi_data))
# Store the results
chi_results <- rbind(chi_results, data.frame(
Class = class_name,
Year1 = year1,
Year2 = year2,
Chi_sq = chi_test$statistic,
p_value = chi_test$p.value
))
}
}
}
}
# View the results
print(chi_results)
# View the results
print(chi_results)
View(chi_results)
# Get unique years
years <- unique(ImageryAreas_long$Year)
years <- sort(as.numeric(years))  # Ensure years are sorted numerically
# Initialize a dataframe to store results
chi_results <- data.frame(Class = character(),
Year1 = integer(),
Year2 = integer(),
Chi_sq = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each class
for (class_name in unique(ImageryAreas_long$Class)) {
# Loop through pairs of years (e.g., 2010 vs 2013, 2010 vs 2015, etc.)
for (i in 1:(length(years) - 1)) {
for (j in (i + 1):length(years)) {
year1 <- years[i]
year2 <- years[j]
# Filter data for the specific class and years
chi_data <- ImageryAreas_long %>%
filter(Class == class_name & Year %in% c(year1, year2)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area), .groups = "drop") %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
# Ensure data exists for the two years being compared
if (nrow(chi_data) > 0 && all(!is.na(chi_data))) {
# Perform chi-squared test
chi_test <- chisq.test(as.matrix(chi_data))
# Store the results
chi_results <- rbind(chi_results, data.frame(
Class = class_name,
Year1 = year1,
Year2 = year2,
Chi_sq = chi_test$statistic,
p_value = chi_test$p.value
))
}
}
}
}
# View the results
print(chi_results)
View(chi_results)
chi_results_sorted <- chi_results %>%
arrange(p_value)
# If you want to sort by the adjusted p-values (e.g., after applying Bonferroni correction)
chi_results_sorted_adj <- chi_results %>%
mutate(adj_p_value = p.adjust(p_value, method = "bonferroni")) %>%
arrange(adj_p_value)
# Print the sorted results
print(chi_results_sorted)
print(chi_results_sorted_adj)
View(chi_results_sorted_adj)
ImageryAreas_long_Sheep <- ImageryAreas_long %>%
filter(grepl("\\.0$", Year))
View(ImageryAreas_long_Sheep)
str(ImageryAreas_long_Sheep)
ImageryAreas_long_Sheep <- ImageryAreas_long %>%
filter(grepl("\\.0$", as.character(Year)))
str(ImageryAreas_long_Sheep)
str(ImageryAreas_long)
str(ImageryAreas_long)
View(ImageryAreas_long_Sheep)
ImageryAreas_long_Sheep <- ImageryAreas_long %>%
filter(grepl("\\.0$", as.character(Year)))
str(ImageryAreas_long_Sheep)
# Get unique years
years <- unique(ImageryAreas_long$Year)
# Inspect the unique values of the 'Year' column
unique(ImageryAreas_long$Year)
# Filter for years that end with .0
ImageryAreas_long_Sheep <- ImageryAreas_long %>%
filter(grepl("\\.0$", as.character(Year)))
# Check the filtered data
str(ImageryAreas_long_Sheep)
unique(as.character(ImageryAreas_long$Year))
# Filter for years that end with .0
ImageryAreas_long_Sheep <- ImageryAreas_long %>%
filter(grepl("\\.0$", as.character(Year)))
# Check the filtered data
str(ImageryAreas_long_Sheep)
ImageryAreas_long_Sheep <- ImageryAreas_long %>%
filter(Year %% 1 == 0)  # This keeps only the whole years (without decimals)
# Check the filtered data
str(ImageryAreas_long_Sheep)
years <- unique(ImageryAreas_long$Year)
years <- sort(as.numeric(years))  # Ensure years are sorted numerically
# Initialize a dataframe to store results
chi_results <- data.frame(Class = character(),
Year1 = integer(),
Year2 = integer(),
Chi_sq = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each class
for (class_name in unique(ImageryAreas_long_Sheep$Class)) {
# Loop through pairs of years (e.g., 2010 vs 2013, 2010 vs 2015, etc.)
for (i in 1:(length(years) - 1)) {
for (j in (i + 1):length(years)) {
year1 <- years[i]
year2 <- years[j]
# Filter data for the specific class and years
chi_data <- ImageryAreas_long %>%
filter(Class == class_name & Year %in% c(year1, year2)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area), .groups = "drop") %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
# Ensure data exists for the two years being compared
if (nrow(chi_data) > 0 && all(!is.na(chi_data))) {
# Perform chi-squared test
chi_test <- chisq.test(as.matrix(chi_data))
# Store the results
chi_results <- rbind(chi_results, data.frame(
Class = class_name,
Year1 = year1,
Year2 = year2,
Chi_sq = chi_test$statistic,
p_value = chi_test$p.value
))
}
}
}
}
# View the results
print(chi_results)
# Sorting by p_value in ascending order to show the smallest (most significant) p-values first
chi_results_sorted <- chi_results %>%
arrange(p_value)
# If you want to sort by the adjusted p-values (e.g., after applying Bonferroni correction)
chi_results_sorted_adj <- chi_results %>%
mutate(adj_p_value = p.adjust(p_value, method = "bonferroni")) %>%
arrange(adj_p_value)
# Print the sorted results
print(chi_results_sorted)
print(chi_results_sorted_adj)
View(chi_results_sorted_adj)
years <- unique(ImageryAreas_long_Sheep$Year)
years <- sort(as.numeric(years))  # Ensure years are sorted numerically
# Initialize a dataframe to store results
chi_results <- data.frame(Class = character(),
Year1 = integer(),
Year2 = integer(),
Chi_sq = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each class
for (class_name in unique(ImageryAreas_long_Sheep$Class)) {
# Loop through pairs of years (e.g., 2010 vs 2013, 2010 vs 2015, etc.)
for (i in 1:(length(years) - 1)) {
for (j in (i + 1):length(years)) {
year1 <- years[i]
year2 <- years[j]
# Filter data for the specific class and years
chi_data <- ImageryAreas_long %>%
filter(Class == class_name & Year %in% c(year1, year2)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area), .groups = "drop") %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
# Ensure data exists for the two years being compared
if (nrow(chi_data) > 0 && all(!is.na(chi_data))) {
# Perform chi-squared test
chi_test <- chisq.test(as.matrix(chi_data))
# Store the results
chi_results <- rbind(chi_results, data.frame(
Class = class_name,
Year1 = year1,
Year2 = year2,
Chi_sq = chi_test$statistic,
p_value = chi_test$p.value
))
}
}
}
}
# View the results
print(chi_results)
# Sorting by p_value in ascending order to show the smallest (most significant) p-values first
chi_results_sorted <- chi_results %>%
arrange(p_value)
# If you want to sort by the adjusted p-values (e.g., after applying Bonferroni correction)
chi_results_sorted_adj <- chi_results %>%
mutate(adj_p_value = p.adjust(p_value, method = "bonferroni")) %>%
arrange(adj_p_value)
# Print the sorted results
print(chi_results_sorted)
print(chi_results_sorted_adj)
View(chi_results_sorted_adj)
chi_results_sorted_adj %>%
filter(Class == "Forest")
View(chi_results_sorted_adj)
ImageryAreas_long_Childs <- ImageryAreas_long %>%
filter(grepl("\\.1$", as.character(Year)))
View(ImageryAreas_long_Childs)
ImageryAreas_long_BRAP <- ImageryAreas_long %>%
filter(grepl("\\.2$", as.character(Year)))
View(ImageryAreas_long_BRAP)
ImageryAreas <- read.csv("ImageryStatistics150mforR.csv")
=======
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
#Coef
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
# Full model predictions
full_probabilities <- predict(model, test_data, type = "response")
full_predicted <- ifelse(full_probabilities > 0.5, 1, 0)
# Stepwise model predictions
step_probabilities <- predict(step.model, test_data, type = "response")
step_predicted <- ifelse(step_probabilities > 0.5, 1, 0)
# Model accuracy
# Observed outcomes
observed <- test_data$Fall2024
# Accuracy
full_accuracy <- mean(full_predicted == observed)
step_accuracy <- mean(step_predicted == observed)
cat("Full model accuracy:", full_accuracy, "\n")
cat("Stepwise model accuracy:", step_accuracy, "\n")
#Read datafile into r
BeasleyPopSurv <- read.csv("regression.csv")
#Read datafile into r
BeasleyPopSurv <- read.csv("regression.csv")
ChildsPopSurv <- read.csv("ChildsRegresssion.csv")
#Create polynomial terms for possible inclusion into logistic model (for bell-shaped model fit)
#For Beasley
#Polynomial
BeasleyPopSurv$LightBINOM <- BeasleyPopSurv$Light^2
BeasleyPopSurv$HerbaceausBINOM <- BeasleyPopSurv$Herbaceaus^2
BeasleyPopSurv$WaterSurfaceElevationBINOM <- BeasleyPopSurv$WaterSurfaceElevation^2
BeasleyPopSurv$FinesBinom <- BeasleyPopSurv$Fines^2
#For Childs
ChildsPopSurv$LightBINOM <- ChildsPopSurv$Light^2
ChildsPopSurv$HerbaceausBINOM <- ChildsPopSurv$Herbaceaus^2
ChildsPopSurv$FinesBINOM <- ChildsPopSurv$Fines^2
#Brap#
BeasLogit1 <- glm(Fall2024 ~ LightBINOM + HerbaceausBINOM + FinesBinom, data = BeasleyPopSurv, family = "binomial")
#BeasLogit <- glm(TF ~ DistChan + DistChan2 + DGW + DGW2 + PercFines + PercFines2, data = BeasleyPopSurv, family = "binomial")
summary(BeasLogit1)
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(BeasleyPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- BeasleyPopSurv[train_indices, ]
test_data <- BeasleyPopSurv[-train_indices, ]
observed <- BeasleyPopSurv$Fall2024
#+ Herbaceaus + HerbaceausBINOM + LightBINOM + Light
#BRAP
model <- glm(`Fall2024` ~ LightBINOM + HerbaceausBINOM + FinesBinom  ,
data = BeasleyPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
library(ggplot2)
library(dplyr)
library(aod)
library(glm2)
library(MASS)
library(readxl)
install.packages("pscl", repos = "http://cran.us.r-project.org")
library(pscl)
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(BeasleyPopSurv), size = 0.7 * nrow(BeasleyPopSurv))
train_data <- BeasleyPopSurv[train_indices, ]
test_data <- BeasleyPopSurv[-train_indices, ]
observed <- BeasleyPopSurv$Fall2024
#+ Herbaceaus + HerbaceausBINOM + LightBINOM + Light
#BRAP
model <- glm(`Fall2024` ~ LightBINOM + HerbaceausBINOM + FinesBinom  ,
data = BeasleyPopSurv, family = binomial)
# Stepwise model selection (MASS package)
step.model <- stepAIC(model, direction = "both",
trace = FALSE)
coef(model)
coef(step.model)
# Summarize the final selected model
summary(model)
summary(step.model)
library(ggplot2)
library(dplyr)
library(aod)
library(glm2)
library(MASS)
library(readxl)
install.packages("pscl", repos = "http://cran.us.r-project.org")
library(pscl)
install.packages("caret", dependencies = TRUE)
library(caret)
library(pROC)
library(pscl)
BeasleyPopSurv <- read.csv("regression.csv")
ChildsPopSurv <- read.csv("ChildsRegresssion.csv")
install.packages("caret", dependencies = TRUE)
BeasleyPopSurv$LightBINOM <- BeasleyPopSurv$Light^2
BeasleyPopSurv$HerbaceausBINOM <- BeasleyPopSurv$Herbaceaus^2
BeasleyPopSurv$WaterSurfaceElevationBINOM <- BeasleyPopSurv$WaterSurfaceElevation^2
BeasleyPopSurv$FinesBinom <- BeasleyPopSurv$Fines^2
ChildsPopSurv$LightBINOM <- ChildsPopSurv$Light^2
ChildsPopSurv$HerbaceausBINOM <- ChildsPopSurv$Herbaceaus^2
ChildsPopSurv$FinesBINOM <- ChildsPopSurv$Fines^2
BeasleyPopSurv$LightBINOM_scaled <- scale(BeasleyPopSurv$LightBINOM)
BeasLogit3 <- glm(Fall2024 ~ LightBINOM_scaled + I(LightBINOM_scaled^2) + HerbaceausBINOM + FinesBinom,
data = BeasleyPopSurv, family = "binomial")
pred_probs <- predict(BeasLogit3, type = "response")
# Convert probabilities to binary predictions (threshold = 0.5)
pred_class <- ifelse(pred_probs > 0.59, 1, 0)
# Compute accuracy
accuracy <- mean(pred_class == BeasleyPopSurv$Fall2024)
# Generate confusion matrix
conf_matrix <- confusionMatrix(as.factor(pred_class), as.factor(BeasleyPopSurv$Fall2024))
# Compute ROC and AUC
roc_curve <- roc(BeasleyPopSurv$Fall2024, pred_probs)
auc_value <- auc(roc_curve)
# Compute McFadden's Pseudo R²
pseudo_r2 <- pR2(BeasLogit3)["McFadden"]
# Print results
print(conf_matrix)  # Confusion matrix with precision, recall, etc.
cat("Accuracy:", accuracy, "\n")
cat("AUC:", auc_value, "\n")
cat("McFadden's R²:", pseudo_r2, "\n")
# Plot ROC curve
plot(roc_curve, col = "blue", main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
ggplot(data = BeasleyPopSurv, aes(x = LightBINOM, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
ggplot(data = BeasleyPopSurv, aes(x = FinesBinom, y = Fall2024)) +
geom_point() +
stat_smooth(method = "glm", color = "purple", se = FALSE,
method.args = list(family = binomial))
library(tidyverse)
library(tidyr)
library(dplyr)
ImageryAreas <- read.csv("ImageryStatistics150mforR.csv")
# Convert data to long format for analysis
>>>>>>> Stashed changes
ImageryAreas_long <- ImageryAreas %>%
pivot_longer(
cols = starts_with("X"),  # Select columns with year names (e.g., X2023, X2021)
names_to = "Year",
values_to = "Area"
) %>%
mutate(Year = as.numeric(str_remove(Year, "X")))  # Convert "X2023" -> 2023 (numeric)
ImageryAreas_long_Sheep <- ImageryAreas_long %>%
filter(Year %% 1 == 0)  # This keeps only the whole years (without decimals)
ImageryAreas_long_Childs <- ImageryAreas_long %>%
filter(grepl("\\.1$", as.character(Year)))  # This keeps only the whole years (without decimals)
ImageryAreas_long_BRAP <- ImageryAreas_long %>%
filter(grepl("\\.2$", as.character(Year)))
<<<<<<< Updated upstream
years <- unique(ImageryAreas_long_Sheep$Year)
=======
# Get unique years
years <- unique(ImageryAreas_long_BRAP$Year)
>>>>>>> Stashed changes
years <- sort(as.numeric(years))  # Ensure years are sorted numerically
# Initialize a dataframe to store results
chi_results <- data.frame(Class = character(),
Year1 = integer(),
Year2 = integer(),
Chi_sq = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each class
<<<<<<< Updated upstream
for (class_name in unique(ImageryAreas_long_Sheep$Class)) {
=======
for (class_name in unique(ImageryAreas_long_BRAP$Class)) {
>>>>>>> Stashed changes
# Loop through pairs of years (e.g., 2010 vs 2013, 2010 vs 2015, etc.)
for (i in 1:(length(years) - 1)) {
for (j in (i + 1):length(years)) {
year1 <- years[i]
year2 <- years[j]
# Filter data for the specific class and years
chi_data <- ImageryAreas_long %>%
filter(Class == class_name & Year %in% c(year1, year2)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area), .groups = "drop") %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
# Ensure data exists for the two years being compared
if (nrow(chi_data) > 0 && all(!is.na(chi_data))) {
# Perform chi-squared test
chi_test <- chisq.test(as.matrix(chi_data))
# Store the results
chi_results <- rbind(chi_results, data.frame(
Class = class_name,
Year1 = year1,
Year2 = year2,
Chi_sq = chi_test$statistic,
p_value = chi_test$p.value
))
}
}
}
}
# View the results
print(chi_results)
<<<<<<< Updated upstream
# Sorting by p_value in ascending order to show the smallest (most significant) p-values first
=======
>>>>>>> Stashed changes
chi_results_sorted <- chi_results %>%
arrange(p_value)
# If you want to sort by the adjusted p-values (e.g., after applying Bonferroni correction)
chi_results_sorted_adj <- chi_results %>%
mutate(adj_p_value = p.adjust(p_value, method = "bonferroni")) %>%
arrange(adj_p_value)
# Print the sorted results
print(chi_results_sorted_adj)
chi_results_sorted_adj %>%
filter(Class == "Forest")
<<<<<<< Updated upstream
View(chi_results_sorted_adj)
=======
chi_results_sorted_adj %>%
filter(Class == "Water")
>>>>>>> Stashed changes
significant_changes_count <- chi_results_sorted_adj %>%
filter(adj_p_value < 0.05) %>%  # Only consider significant changes
group_by(Class) %>%             # Group by Class
summarise(Significant_Changes = n())  # Count the number of significant changes
# View the result
print(significant_changes_count)
<<<<<<< Updated upstream
specific_years_comparison <- chi_results_sorted_adj %>%
filter((Year1 == "2010" & Year2 == "2023") | (Year1 == "2023" & Year2 == "2010"))
# View the filtered results
print(specific_years_comparison)
specific_years_comparison <- chi_results_sorted_adj %>%
filter((Year1 == "2021" & Year2 == "2023") | (Year1 == "2023" & Year2 == "2010"))
# View the filtered results
print(specific_years_comparison)
specific_years_comparison <- chi_results_sorted_adj %>%
filter((Year1 == "2021" & Year2 == "2023") | (Year1 == "2023" & Year2 == "2021"))
# View the filtered results
print(specific_years_comparison)
# View the result
print(significant_changes_count)
=======
chi_results_sorted_adj %>%
filter(Class == "Barren")
chi_results_sorted_adj %>%
filter(Class == "Upland Forest")
significant_changes_count <- chi_results_sorted_adj %>%
filter(adj_p_value < 0.05) %>%  # Only consider significant changes
group_by(Class) %>%             # Group by Class
summarise(Significant_Changes = n())  # Count the number of significant changes
# View the result
print(significant_changes_count)
chi_results_sorted_adj %>%
filter(Class == "Shadow")
chi_results_sorted_adj %>%
filter(Class == "Shadow")
chi_results_sorted_adj %>%
filter(Class == "Shrubland")
chi_results_sorted_adj %>%
filter(Class == "Upland Forest")
chi_results_sorted_adj %>%
filter(Class == "Upland Forest")
chi_results_sorted_adj
>>>>>>> Stashed changes
years <- unique(ImageryAreas_long_Childs$Year)
years <- sort(as.numeric(years))  # Ensure years are sorted numerically
# Initialize a dataframe to store results
chi_results <- data.frame(Class = character(),
Year1 = integer(),
Year2 = integer(),
Chi_sq = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each class
for (class_name in unique(ImageryAreas_long_Childs$Class)) {
# Loop through pairs of years (e.g., 2010 vs 2013, 2010 vs 2015, etc.)
for (i in 1:(length(years) - 1)) {
for (j in (i + 1):length(years)) {
year1 <- years[i]
year2 <- years[j]
# Filter data for the specific class and years
chi_data <- ImageryAreas_long %>%
filter(Class == class_name & Year %in% c(year1, year2)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area), .groups = "drop") %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
# Ensure data exists for the two years being compared
if (nrow(chi_data) > 0 && all(!is.na(chi_data))) {
# Perform chi-squared test
chi_test <- chisq.test(as.matrix(chi_data))
# Store the results
chi_results <- rbind(chi_results, data.frame(
Class = class_name,
Year1 = year1,
Year2 = year2,
Chi_sq = chi_test$statistic,
p_value = chi_test$p.value
))
}
}
}
}
# View the results
print(chi_results)
<<<<<<< Updated upstream
# Sorting by p_value in ascending order to show the smallest (most significant) p-values first
chi_results_sorted <- chi_results %>%
arrange(p_value)
chi_results_sorted_adj <- chi_results %>%
mutate(adj_p_value = p.adjust(p_value, method = "bonferroni")) %>%
arrange(adj_p_value)
# Print the sorted results
print(chi_results_sorted_adj)
chi_results_sorted_adj %>%
filter(Class == "Forest")
# Count the number of significant changes (where adj_p_value < 0.05) for each class
=======
>>>>>>> Stashed changes
significant_changes_count <- chi_results_sorted_adj %>%
filter(adj_p_value < 0.05) %>%  # Only consider significant changes
group_by(Class) %>%             # Group by Class
summarise(Significant_Changes = n())  # Count the number of significant changes
# View the result
print(significant_changes_count)
<<<<<<< Updated upstream
=======
chi_results_sorted_adj <- chi_results %>%
mutate(adj_p_value = p.adjust(p_value, method = "bonferroni")) %>%
arrange(adj_p_value)
# Print the sorted results
print(chi_results_sorted_adj)
chi_results_sorted_adj %>%
filter(Class == "Upland Forest")
chi_results_sorted_adj %>%
filter(Class == "Upland Forest")
chi_results_sorted_adj
chi_results_sorted_adj %>%
filter(Class == "Shrubland")
years <- unique(ImageryAreas_long_Sheep$Year)
years <- sort(as.numeric(years))  # Ensure years are sorted numerically
# Initialize a dataframe to store results
chi_results <- data.frame(Class = character(),
Year1 = integer(),
Year2 = integer(),
Chi_sq = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each class
for (class_name in unique(ImageryAreas_long_Sheep$Class)) {
# Loop through pairs of years (e.g., 2010 vs 2013, 2010 vs 2015, etc.)
for (i in 1:(length(years) - 1)) {
for (j in (i + 1):length(years)) {
year1 <- years[i]
year2 <- years[j]
# Filter data for the specific class and years
chi_data <- ImageryAreas_long %>%
filter(Class == class_name & Year %in% c(year1, year2)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area), .groups = "drop") %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
# Ensure data exists for the two years being compared
if (nrow(chi_data) > 0 && all(!is.na(chi_data))) {
# Perform chi-squared test
chi_test <- chisq.test(as.matrix(chi_data))
# Store the results
chi_results <- rbind(chi_results, data.frame(
Class = class_name,
Year1 = year1,
Year2 = year2,
Chi_sq = chi_test$statistic,
p_value = chi_test$p.value
))
}
}
}
}
# View the results
print(chi_results)
chi_results_sorted <- chi_results %>%
arrange(p_value)
chi_results_sorted_adj <- chi_results %>%
mutate(adj_p_value = p.adjust(p_value, method = "bonferroni")) %>%
arrange(adj_p_value)
significant_changes_count <- chi_results_sorted_adj %>%
filter(adj_p_value < 0.05) %>%  # Only consider significant changes
group_by(Class) %>%             # Group by Class
summarise(Significant_Changes = n())  # Count the number of significant changes
# View the result
print(significant_changes_count)
chi_results_sorted_adj %>%
filter(Class == "Barren")
# Print the sorted results
print(chi_results_sorted_adj)
library(tidyverse)
library(tidyr)
library(dplyr)
ImageryAreas <- read.csv("ImageryStatistics150mforR.csv")
# Convert data to long format for analysis
ImageryAreas_long <- ImageryAreas %>%
pivot_longer(
cols = starts_with("X"),  # Select columns with year names (e.g., X2023, X2021)
names_to = "Year",
values_to = "Area"
) %>%
mutate(Year = as.numeric(str_remove(Year, "X")))  # Convert "X2023" -> 2023 (numeric)
# Filter for Sheep
ImageryAreas_long_Sheep <- ImageryAreas_long %>%
filter(Year %% 1 == 0)  # This keeps only the whole years (without decimals)
ImageryAreas_long_Childs <- ImageryAreas_long %>%
filter(grepl("\\.1$", as.character(Year)))  # This keeps only the whole years (without decimals)
ImageryAreas_long_BRAP <- ImageryAreas_long %>%
filter(grepl("\\.2$", as.character(Year)))
# Get unique years
>>>>>>> Stashed changes
years <- unique(ImageryAreas_long_BRAP$Year)
years <- sort(as.numeric(years))  # Ensure years are sorted numerically
# Initialize a dataframe to store results
chi_results <- data.frame(Class = character(),
Year1 = integer(),
Year2 = integer(),
Chi_sq = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each class
for (class_name in unique(ImageryAreas_long_BRAP$Class)) {
# Loop through pairs of years (e.g., 2010 vs 2013, 2010 vs 2015, etc.)
for (i in 1:(length(years) - 1)) {
for (j in (i + 1):length(years)) {
year1 <- years[i]
year2 <- years[j]
# Filter data for the specific class and years
chi_data <- ImageryAreas_long %>%
filter(Class == class_name & Year %in% c(year1, year2)) %>%
group_by(Class, Year) %>%
summarise(Total_Area = sum(Area), .groups = "drop") %>%
pivot_wider(names_from = Year, values_from = Total_Area) %>%
column_to_rownames("Class")
# Ensure data exists for the two years being compared
if (nrow(chi_data) > 0 && all(!is.na(chi_data))) {
# Perform chi-squared test
chi_test <- chisq.test(as.matrix(chi_data))
# Store the results
chi_results <- rbind(chi_results, data.frame(
Class = class_name,
Year1 = year1,
Year2 = year2,
Chi_sq = chi_test$statistic,
p_value = chi_test$p.value
))
}
}
}
}
# View the results
print(chi_results)
# Sorting by p_value in ascending order to show the smallest (most significant) p-values first
chi_results_sorted <- chi_results %>%
arrange(p_value)
# If you want to sort by the adjusted p-values (e.g., after applying Bonferroni correction)
chi_results_sorted_adj <- chi_results %>%
mutate(adj_p_value = p.adjust(p_value, method = "bonferroni")) %>%
arrange(adj_p_value)
<<<<<<< Updated upstream
# Print the sorted results
print(chi_results_sorted_adj)
chi_results_sorted_adj %>%
filter(Class == "Forest")
# Count the number of significant changes (where adj_p_value < 0.05) for each class
significant_changes_count <- chi_results_sorted_adj %>%
filter(adj_p_value < 0.05) %>%  # Only consider significant changes
group_by(Class) %>%             # Group by Class
summarise(Significant_Changes = n())  # Count the number of significant changes
# View the result
print(significant_changes_count)
=======
library(ggplot2)
library(dplyr)
library(aod)
library(glm2)
library(MASS)
library(readxl)
install.packages("pscl", repos = "http://cran.us.r-project.org")
library(pscl)
install.packages("caret", dependencies = TRUE)
library(caret)
library(pROC)
library(pscl)
#Look into cross validati
install.packages("caret", dependencies = TRUE)
BeasleyPopSurv <- read.csv("regression.csv")
ChildsPopSurv <- read.csv("ChildsRegresssion.csv")
BeasleyPopSurv$LightBINOM <- BeasleyPopSurv$Light^2
BeasleyPopSurv$HerbaceausBINOM <- BeasleyPopSurv$Herbaceaus^2
BeasleyPopSurv$WaterSurfaceElevationBINOM <- BeasleyPopSurv$WaterSurfaceElevation^2
BeasleyPopSurv$FinesBinom <- BeasleyPopSurv$Fines^2
#For Childs
ChildsPopSurv$LightBINOM <- ChildsPopSurv$Light^2
ChildsPopSurv$HerbaceausBINOM <- ChildsPopSurv$Herbaceaus^2
ChildsPopSurv$FinesBINOM <- ChildsPopSurv$Fines^2
BeasLogit3 <- glm(Fall2024 ~ poly(LightBINOM, 2) + HerbaceausBINOM + FinesBinom, data = BeasleyPopSurv, family = "binomial")
BeasleyPopSurv$LightBINOM_scaled <- scale(BeasleyPopSurv$LightBINOM)
BeasLogit3 <- glm(Fall2024 ~ LightBINOM_scaled + I(LightBINOM_scaled^2) + HerbaceausBINOM + FinesBinom,
data = BeasleyPopSurv, family = "binomial")
summary(BeasLogit3)
optimal_threshold <- coords(roc_curve, "best", ret = "threshold")
cat("Accuracy:", accuracy, "\n")
library(ggplot2)
library(dplyr)
library(aod)
library(glm2)
library(MASS)
library(readxl)
install.packages("pscl", repos = "http://cran.us.r-project.org")
library(pscl)
install.packages("caret", dependencies = TRUE)
library(caret)
library(pROC)
library(pscl)
install.packages("pscl", repos = "http://cran.us.r-project.org")
install.packages("caret", dependencies = TRUE)
library(ggplot2)
library(dplyr)
library(aod)
library(glm2)
library(MASS)
library(readxl)
install.packages("pscl", repos = "http://cran.us.r-project.org")
library(pscl)
install.packages("caret", dependencies = TRUE)
library(caret)
library(pROC)
library(pscl)
BeasLogit3 <- glm(Fall2024 ~ poly(LightBINOM, 2) + HerbaceausBINOM + FinesBinom, data = BeasleyPopSurv, family = "binomial")
BeasleyPopSurv$LightBINOM_scaled <- scale(BeasleyPopSurv$LightBINOM)
BeasLogit3 <- glm(Fall2024 ~ LightBINOM_scaled + I(LightBINOM_scaled^2) + HerbaceausBINOM + FinesBinom,
data = BeasleyPopSurv, family = "binomial")
summary(BeasLogit3)
optimal_threshold <- coords(roc_curve, "best", ret = "threshold")
print(conf_matrix)  # Confusion matrix with precision, recall, etc.
#test for accuracy
pred_probs <- predict(BeasLogit3, type = "response")
# Convert probabilities to binary predictions (threshold = 0.5)
pred_class <- ifelse(pred_probs > 0.59, 1, 0)
# Compute accuracy
accuracy <- mean(pred_class == BeasleyPopSurv$Fall2024)
# Generate confusion matrix
conf_matrix <- confusionMatrix(as.factor(pred_class), as.factor(BeasleyPopSurv$Fall2024))
optimal_threshold <- coords(roc_curve, "best", ret = "threshold")
library(pscl)
library(pROC)
library(caret)
library(pscl)
library(readxl)
library(MASS)
library(glm2)
library(aod)
#test for accuracy
pred_probs <- predict(BeasLogit3, type = "response")
# Convert probabilities to binary predictions (threshold = 0.5)
pred_class <- ifelse(pred_probs > 0.59, 1, 0)
# Compute accuracy
accuracy <- mean(pred_class == BeasleyPopSurv$Fall2024)
# Generate confusion matrix
conf_matrix <- confusionMatrix(as.factor(pred_class), as.factor(BeasleyPopSurv$Fall2024))
# Compute ROC and AUC
roc_curve <- roc(BeasleyPopSurv$Fall2024, pred_probs)
auc_value <- auc(roc_curve)
# Compute McFadden's Pseudo R²
pseudo_r2 <- pR2(BeasLogit3)["McFadden"]
# Print results
print(conf_matrix)  # Confusion matrix with precision, recall, etc.
cat("Accuracy:", accuracy, "\n")
cat("AUC:", auc_value, "\n")
cat("McFadden's R²:", pseudo_r2, "\n")
>>>>>>> Stashed changes
